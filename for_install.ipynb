{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Нужные установки"
      ],
      "metadata": {
        "id": "ifOZnyHUMxTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyLDAvis"
      ],
      "metadata": {
        "id": "Mtv0AM82bJ_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "parser = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "56dj8TTfLZRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece"
      ],
      "metadata": {
        "id": "7AfNV1Px9i_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "nltk.download(\"stopwords\") # поддерживает удаление стоп-слов\n",
        "nltk.download('punkt') # делит текст на список предложений\n",
        "nltk.download('wordnet') # проводит лемматизацию"
      ],
      "metadata": {
        "id": "g55WGgnLUgFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd             \n",
        "import numpy as np               \n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as sns            \n",
        "#import datetime                  \n",
        "import pickle\n",
        "from wordcloud import WordCloud  # Пакет для построения облаков слов\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "import gensim\n",
        "from gensim import corpora, models\n",
        "from ast import literal_eval"
      ],
      "metadata": {
        "id": "XbWJXj9Lep1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "rbo5UYoB9xbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis"
      ],
      "metadata": {
        "id": "_dn123JEbQWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import download as nltk_download "
      ],
      "metadata": {
        "id": "9HAAUoSDfcuB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}